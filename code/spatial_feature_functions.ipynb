{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe4aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e052b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def PolynomialGeographicCoordinates(data, parameters, regio=None):\n",
    "    '''\n",
    "    The function converts the 'x' and 'y' columns of the 'data' DataFrame into a numpy array \n",
    "    and applies a 4th degree polynomial transformation on it. The result of the transformation is added \n",
    "    as new columns to the original 'data' DataFrame, and the '1st', 'x', and 'y' columns are dropped. \n",
    "    '''\n",
    "    # Convert 'x' and 'y' columns to a numpy array\n",
    "    points_poly = data[['x', 'y']].to_numpy()\n",
    "    \n",
    "    # Apply 4th degree polynomial transformation\n",
    "    poly = PolynomialFeatures(degree=4)\n",
    "    data_poly = poly.fit_transform(points_poly)\n",
    "    \n",
    "    # Create a DataFrame with the transformed data\n",
    "    data_poly = pd.DataFrame(data_poly, columns=['1','x','y','x^2','xy','y^2','x^3','x^2y','xy^2','y^3','x^4','x^3y','x^2y^2','xy^3','y^4'])\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    data_poly.drop(columns=['1', 'x','y'], inplace=True)\n",
    "    \n",
    "    # Join the transformed data with the original data\n",
    "    data_poly = data.join(data_poly)\n",
    "    \n",
    "    # Convert column names to string type\n",
    "    data_poly.columns = data_poly.columns.astype(str)\n",
    "    \n",
    "    return data_poly\n",
    "\n",
    "def ObliqueGeographicCoordinates(data, parameters, regio=None):\n",
    "    '''\n",
    "    The function adds oblique coordinates (0-180 degrees, with intervals of 5 degrees) to a data set.\n",
    "    It takes the input data and parameters, converts the 'x' and 'y' coordinates to numpy arrays, \n",
    "    calculates the oblique coordinates using trigonometry, and returns the data with the added \n",
    "    oblique coordinates.\n",
    "    '''\n",
    "    # Get parameters for oblique coordinates\n",
    "    start, step, stop = parameters['OGC']\n",
    "    \n",
    "    # Calculate angles in degrees and radians\n",
    "    angles_deg = np.arange(start=start, step=step, stop=stop)\n",
    "    angles_rad = np.radians(angles_deg)\n",
    "    \n",
    "    # Convert 'x' and 'y' columns to numpy arrays\n",
    "    x = data[['x']].to_numpy()\n",
    "    y = data[['y']].to_numpy()\n",
    "    \n",
    "    # Calculate oblique coordinates for each angle\n",
    "    for i in angles_rad:\n",
    "        OGC = np.sqrt(x**2 + y**2) * np.cos(angles_rad - np.arctan(x/y))\n",
    "    \n",
    "    # Create a DataFrame with the oblique coordinates\n",
    "    OGC = pd.DataFrame(OGC)\n",
    "    \n",
    "    # Reset the index of the original data\n",
    "    data.reset_index(inplace=True)\n",
    "    \n",
    "    # Join the oblique coordinates with the original data\n",
    "    data_OGC = data.join(OGC)\n",
    "    \n",
    "    # Convert column names to string type\n",
    "    data_OGC.columns = data_OGC.columns.astype(str)\n",
    "    \n",
    "    return data_OGC\n",
    "\n",
    "def WTC_kernel(normalized_lon, normalized_lat, n):\n",
    "    # Define the number of basis functions\n",
    "    num_basis = [n ** 2, (2*n) ** 2, (4*n) ** 2]\n",
    "    \n",
    "    # Define the knots for each basis function\n",
    "    knots_1dx = [np.linspace(0, 1, int(np.sqrt(i))) for i in num_basis]\n",
    "    knots_1dy = [np.linspace(0, 1, int(np.sqrt(i))) for i in num_basis]\n",
    "    \n",
    "    # Initialize the phi matrix\n",
    "    basis_size = 0\n",
    "    phi = np.zeros((normalized_lon.shape[0], sum(num_basis)))\n",
    "    \n",
    "    # Compute the weight functions for each basis function\n",
    "    for res in range(len(num_basis)):\n",
    "        theta = 1 / np.sqrt(num_basis[res]) * 2.5\n",
    "        knots_x, knots_y = np.meshgrid(knots_1dx[res], knots_1dy[res])\n",
    "        knots = np.column_stack((knots_x.flatten(), knots_y.flatten()))\n",
    "        \n",
    "        for i in range(num_basis[res]):\n",
    "            d = np.linalg.norm(np.vstack((normalized_lon, normalized_lat)).T - knots[i, :], axis=1) / theta\n",
    "            \n",
    "            for j in range(len(d)):\n",
    "                if 0 <= d[j] <= 1:\n",
    "                    phi[j, i + basis_size] = (1 - d[j]) ** 6 * (35 * d[j] ** 2 + 18 * d[j] + 3) / 3\n",
    "                else:\n",
    "                    phi[j, i + basis_size] = 0\n",
    "        \n",
    "        basis_size = basis_size + num_basis[res]\n",
    "    \n",
    "    return phi\n",
    "\n",
    "def WendlandTransformedCoordinates(data, parameters, regio=None):\n",
    "    '''\n",
    "    The function applies Wendland Transform to the input data set.\n",
    "    It takes the data, parameters, and regio as input.\n",
    "    It calculates the normalized coordinates based on 'x' and 'y' columns.\n",
    "    It calls the WTC_kernel function to calculate the kernel values.\n",
    "    It returns the data set with the added transformed coordinates.\n",
    "    '''\n",
    "    # Get the value of 'n' parameter for WTC\n",
    "    n = parameters['WTC']\n",
    "    \n",
    "    # Normalize 'x' and 'y' coordinates\n",
    "    Rechts = (data['x'] - np.min(data['x'])) / (np.max(data['x']) - np.min(data['x']))\n",
    "    Hoch = (data['y'] - np.min(data['y'])) / (np.max(data['y']) - np.min(data['y']))\n",
    "    \n",
    "    # Calculate WTC kernel\n",
    "    WTC = WTC_kernel(Rechts, Hoch, n)\n",
    "    \n",
    "    # Create a modified data set by joining the WTC matrix with the original data\n",
    "    data_mod = data\n",
    "    data_mod_1 = pd.concat([data_mod.reset_index(), pd.DataFrame(WTC, columns=np.arange(WTC.shape[1]).astype('str'))], axis=1)\n",
    "    \n",
    "    # Convert column names to string type\n",
    "    data_mod_1.columns = data_mod_1.columns.astype(str)\n",
    "    \n",
    "    return data_mod_1\n",
    "\n",
    "def EuclideanDistanceFields(data, parameters, regio=None):\n",
    "    '''\n",
    "    Calculates the Euclidean distances between each point in the 'x' and 'y' columns of the input DataFrame\n",
    "    and the four corners (upper left, upper right, bottom left, and bottom right) and the center \n",
    "    of the study area. The distances are added as new columns 'NW', 'NE', 'SW', 'SE', and 'C' to the input data DataFrame, and the resulting DataFrame is returned. The function is optimized by using vectorized operations from NumPy and avoiding redundant calculations.\n",
    "    '''\n",
    "    # Calculate minimum and maximum coordinates\n",
    "    xmin, ymin = data[['x', 'y']].min()\n",
    "    xmax, ymax = data[['x', 'y']].max()\n",
    "    \n",
    "    # Calculate the mean coordinates\n",
    "    xmid = data.x.mean()\n",
    "    ymid = data.y.mean()\n",
    "    \n",
    "    # Convert 'x' and 'y' columns to numpy array\n",
    "    points = data[['x', 'y']].values\n",
    "    \n",
    "    # Define the four corners and center of the study area\n",
    "    SW = np.array([xmin, ymin])\n",
    "    SE = np.array([xmax, ymin])\n",
    "    NE = np.array([xmax, ymax])\n",
    "    NW = np.array([xmin, ymax])\n",
    "    C = np.array([xmid, ymid])\n",
    "    \n",
    "    # Calculate Euclidean distances for each point and corner/center\n",
    "    dm_SW = np.linalg.norm(points - SW, axis=1)\n",
    "    dm_SE = np.linalg.norm(points - SE, axis=1)\n",
    "    dm_NE = np.linalg.norm(points - NE, axis=1)\n",
    "    dm_NW = np.linalg.norm(points - NW, axis=1)\n",
    "    dm_C = np.linalg.norm(points - C, axis=1)\n",
    "    \n",
    "    # Create a DataFrame with the distances\n",
    "    data_EDF = data.assign(SW=dm_SW, SE=dm_SE, NE=dm_NE, NW=dm_NW, C=dm_C)\n",
    "    \n",
    "    # Check if EDF normalization is enabled\n",
    "    if parameters.get('EDF', False):\n",
    "        # Normalize each column separately\n",
    "        for col in ['SW', 'SE', 'NE', 'NW', 'C']:\n",
    "            max_val = np.max(data_EDF[col])\n",
    "            if max_val > 0:\n",
    "                data_EDF[col] = data_EDF[col] / max_val\n",
    "    \n",
    "    return data_EDF\n",
    "\n",
    "def EuclideanDistanceMatrix(data, parameters, regio=None):\n",
    "    '''\n",
    "    The function calculates the Euclidean distance between each pair of points in the 'x' \n",
    "    and 'y' columns of the input 'data' DataFrame and adds the resulting distance matrix or PCA transformed \n",
    "    matrix as new columns to the 'data' DataFrame. If the 'EDM' parameter is True, PCA transformation is \n",
    "    applied to the distance matrix with the specified number of components. The final result is a DataFrame with \n",
    "    the original columns of 'data' and the distance matrix/PCA transformed matrix.\n",
    "    '''\n",
    "    # Convert 'x' and 'y' columns to numpy array\n",
    "    points_coords = data[['x', 'y']].to_numpy()\n",
    "    \n",
    "    # Check if regio is provided for distance calculation\n",
    "    if regio is not None:\n",
    "        points1_coords = regio[['x', 'y']].to_numpy()\n",
    "        dm = cdist(points_coords, points1_coords, metric='euclidean')\n",
    "    else:\n",
    "        dm = cdist(points_coords, points_coords, metric='euclidean')\n",
    "    \n",
    "    # Check if EDM normalization is enabled\n",
    "    if parameters.get('EDM', False):\n",
    "        dm = dm / np.max(dm)\n",
    "    \n",
    "    # Create a DataFrame with the distance matrix\n",
    "    result = np.hstack([data, dm])\n",
    "    result = pd.DataFrame(result, columns=data.columns.tolist() + ['dist_' + str(i) for i in range(dm.shape[1])])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def PrincipleComponentAnalysis(data, parameters, regio=None):\n",
    "    '''\n",
    "    This implementation uses the PCA class from the sklearn.decomposition module to perform PCA on\n",
    "    the input data. The fit_transform method is used to fit the PCA model to the input data and to\n",
    "    obtain the transformed data in a lower-dimensional space. The n_components argument specifies\n",
    "    the number of dimensions in the reduced space, with a default value of 2 for easy visualization.\n",
    "    '''\n",
    "    normalize = True\n",
    "    n_components = int(parameters['PCA'])\n",
    "    \n",
    "    # Convert 'x' and 'y' columns to numpy array\n",
    "    points_coords = data[['x', 'y']].to_numpy()\n",
    "    \n",
    "    # Check if regio is provided for distance calculation\n",
    "    if regio is not None:\n",
    "        points1_coords = regio[['x', 'y']].to_numpy()\n",
    "        dm = cdist(points_coords, points1_coords, metric='euclidean')\n",
    "    else:\n",
    "        dm = cdist(points_coords, points_coords, metric='euclidean')\n",
    "    \n",
    "    # Normalize the distance matrix if enabled\n",
    "    if normalize:\n",
    "        dm = StandardScaler().fit_transform(dm)\n",
    "    \n",
    "    # Perform PCA transformation\n",
    "    pca = PCA(n_components=n_components)\n",
    "    transformed_data = pca.fit_transform(dm)\n",
    "    \n",
    "    # Create a DataFrame with the transformed data\n",
    "    PC = pd.DataFrame(transformed_data)\n",
    "    data_PCA = data.join(PC)\n",
    "    \n",
    "    # Convert column names to string type\n",
    "    data_PCA.columns = data_PCA.columns.astype(str)\n",
    "    \n",
    "    return data_PCA\n",
    "\n",
    "def EigenvectorSpatialFiltering(data, parameters, regio=None):\n",
    "    '''\n",
    "    The function applies Eigenvector Spatial Filtering (ESF) to the input data set.\n",
    "    It takes the data, parameters, and regio as input.\n",
    "    It calculates the Euclidean distances between each pair of points.\n",
    "    It performs Singular Value Decomposition (SVD) on the distance matrix.\n",
    "    It selects the first K eigenvectors.\n",
    "    It returns the data set with the added eigenvectors.\n",
    "    '''\n",
    "    # Get parameters for ESF\n",
    "    dmax, k = parameters['ESF']\n",
    "    \n",
    "    # Convert 'x' and 'y' columns to numpy array\n",
    "    points_EV = data[['x', 'y']].to_numpy()\n",
    "    \n",
    "    # Check if regio is provided for distance calculation\n",
    "    if regio is not None:\n",
    "        points1_coords = regio[['x', 'y']].to_numpy()\n",
    "        dm_EV = cdist(points_EV, points1_coords, metric='euclidean')\n",
    "    else:\n",
    "        dm_EV = cdist(points_EV,points_EV, metric='euclidean')\n",
    "    \n",
    "    # Set distances greater than dmax to dmax * 4\n",
    "    dm_EV = np.asarray(dm_EV)\n",
    "    dm_EV[dm_EV > dmax] = dmax * 4\n",
    "    \n",
    "    # Compute SVD of the distance matrix\n",
    "    U, s, Vt = np.linalg.svd(dm_EV, full_matrices=False)\n",
    "    \n",
    "    # Select the first K eigenvectors\n",
    "    eigvec = U[:, :k]\n",
    "    \n",
    "    # Convert eigenvectors array to a DataFrame\n",
    "    eigvec_df = pd.DataFrame(data=eigvec, index=data.index, columns=[f'eigvec_{i+1}' for i in range(k)])\n",
    "    \n",
    "    # Join the eigenvector DataFrame with the original data DataFrame\n",
    "    data_eigvec = pd.concat([data, eigvec_df], axis=1)\n",
    "    \n",
    "    return data_eigvec\n",
    "\n",
    "# Mapping of variables to their corresponding functions\n",
    "functions = {\n",
    "    # Coordinate Based Methods\n",
    "    'PGC': PolynomialGeographicCoordinates,\n",
    "    'OGC': ObliqueGeographicCoordinates,\n",
    "    # Distance Based Methods\n",
    "    'WTC': WendlandTransformedCoordinates,\n",
    "    'EDF': EuclideanDistanceFields,\n",
    "    'EDM': EuclideanDistanceMatrix,\n",
    "    'PCA': PrincipleComponentAnalysis,\n",
    "    'ESF': EigenvectorSpatialFiltering,  \n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
